input {
  # Read application logs from file
  file {
    path => "/logs/*.log"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    codec => "json"
    tags => ["application"]
  }
  
  # Read Docker container logs
  file {
    path => "/var/lib/docker/containers/*/*.log"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    codec => "json"
    tags => ["docker"]
  }
  
  # Listen for syslog
  syslog {
    port => 5000
    tags => ["syslog"]
  }
  
  # Listen for structured logs
  tcp {
    port => 5044
    codec => json_lines
    tags => ["structured"]
  }
}

filter {
  # Parse timestamp
  date {
    match => [ "@timestamp", "ISO8601" ]
  }
  
  # Add hostname
  mutate {
    add_field => { "hostname" => "%{HOSTNAME}" }
  }
  
  # Process application logs
  if "application" in [tags] {
    # Parse application-specific fields
    if [logger_name] {
      mutate {
        add_field => { "service" => "enterprise-ai-strategy" }
      }
    }
    
    # Extract agent execution details
    if [message] =~ /Agent.*executed/ {
      grok {
        match => { "message" => "Agent %{WORD:agent_name} executed.*duration %{NUMBER:duration_ms:float}ms" }
      }
    }
    
    # Extract API request details
    if [message] =~ /\[REQUEST\]/ {
      grok {
        match => { "message" => "\[REQUEST\] %{WORD:method} %{URIPATH:endpoint} - %{NUMBER:status_code:int} - %{NUMBER:response_time:float}ms" }
      }
    }
  }
  
  # Process Docker logs
  if "docker" in [tags] {
    # Extract container name from path
    grok {
      match => { "path" => "/var/lib/docker/containers/%{DATA:container_id}/%{GREEDYDATA}" }
    }
    
    # Parse Docker log format
    json {
      source => "message"
    }
    
    # Clean up Docker-specific fields
    mutate {
      remove_field => [ "stream", "attrs" ]
    }
  }
  
  # Process syslog messages
  if "syslog" in [tags] {
    # Additional syslog parsing can be added here
    mutate {
      add_field => { "log_type" => "system" }
    }
  }
  
  # Add log level classification
  if [level] {
    if [level] == "ERROR" or [level] == "CRITICAL" {
      mutate {
        add_field => { "severity" => "high" }
      }
    } else if [level] == "WARNING" or [level] == "WARN" {
      mutate {
        add_field => { "severity" => "medium" }
      }
    } else {
      mutate {
        add_field => { "severity" => "low" }
      }
    }
  }
  
  # Geolocation for IP addresses (if available)
  if [remote_addr] {
    geoip {
      source => "remote_addr"
      target => "geoip"
    }
  }
  
  # Remove sensitive information
  mutate {
    remove_field => [ "password", "token", "api_key", "secret" ]
  }
}

output {
  # Send to Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "enterprise-ai-strategy-%{+YYYY.MM.dd}"
    template_name => "enterprise-ai-strategy"
    template => "/usr/share/logstash/templates/enterprise-ai-strategy.json"
    template_overwrite => true
  }
  
  # Debug output (can be removed in production)
  if [severity] == "high" {
    stdout {
      codec => rubydebug
    }
  }
  
  # Send critical errors to dead letter queue
  if [level] == "CRITICAL" {
    file {
      path => "/var/log/logstash/critical-errors.log"
      codec => json_lines
    }
  }
}