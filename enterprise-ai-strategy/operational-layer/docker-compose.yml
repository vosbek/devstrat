version: '3.8'

services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: enterprise-ai-postgres
    environment:
      POSTGRES_DB: enterprise_ai_strategy
      POSTGRES_USER: enterprise_ai_user
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-change_this_password}
      POSTGRES_INITDB_ARGS: "--encoding=UTF-8 --lc-collate=en_US.UTF-8 --lc-ctype=en_US.UTF-8"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./database/init.sql:/docker-entrypoint-initdb.d/init.sql
      - ./database/backup:/backup
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U enterprise_ai_user -d enterprise_ai_strategy"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    networks:
      - enterprise-ai-network

  # Redis for caching and session storage
  redis:
    image: redis:7-alpine
    container_name: enterprise-ai-redis
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD:-change_this_password}
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    networks:
      - enterprise-ai-network

  # FastAPI Backend Service
  api:
    build:
      context: .
      dockerfile: Dockerfile.api
    container_name: enterprise-ai-api
    environment:
      - DATABASE_URL=postgresql://enterprise_ai_user:${POSTGRES_PASSWORD:-change_this_password}@postgres:5432/enterprise_ai_strategy
      - REDIS_URL=redis://:${REDIS_PASSWORD:-change_this_password}@redis:6379/0
      - JWT_SECRET=${JWT_SECRET:-your-jwt-secret-change-this}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION:-us-east-1}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - LOG_LEVEL=INFO
      - ENVIRONMENT=production
    volumes:
      - ./logs:/app/logs
      - ./data:/app/data
    ports:
      - "8000:8000"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    networks:
      - enterprise-ai-network

  # React Frontend (Development mode)
  frontend:
    build:
      context: ./web-ui
      dockerfile: Dockerfile
    container_name: enterprise-ai-frontend
    environment:
      - REACT_APP_API_URL=http://localhost:8000
      - REACT_APP_ENVIRONMENT=production
    ports:
      - "3000:3000"
    depends_on:
      - api
    volumes:
      - ./web-ui/src:/app/src
      - ./web-ui/public:/app/public
    restart: unless-stopped
    networks:
      - enterprise-ai-network

  # Nginx Reverse Proxy
  nginx:
    image: nginx:alpine
    container_name: enterprise-ai-nginx
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - ./logs/nginx:/var/log/nginx
    ports:
      - "80:80"
      - "443:443"
    depends_on:
      - api
      - frontend
    restart: unless-stopped
    networks:
      - enterprise-ai-network

  # Prometheus Monitoring
  prometheus:
    image: prom/prometheus:latest
    container_name: enterprise-ai-prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=90d'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./monitoring/alert_rules.yml:/etc/prometheus/alert_rules.yml:ro
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"
    restart: unless-stopped
    networks:
      - enterprise-ai-network

  # Grafana Dashboard
  grafana:
    image: grafana/grafana:latest
    container_name: enterprise-ai-grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
      - GF_SERVER_ROOT_URL=http://localhost:3001
      - GF_INSTALL_PLUGINS=grafana-piechart-panel,grafana-worldmap-panel
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
    ports:
      - "3001:3000"
    depends_on:
      - prometheus
    restart: unless-stopped
    networks:
      - enterprise-ai-network

  # PostgreSQL Exporter for Prometheus
  postgres-exporter:
    image: prometheuscommunity/postgres-exporter
    container_name: enterprise-ai-postgres-exporter
    environment:
      DATA_SOURCE_NAME: "postgresql://enterprise_ai_user:${POSTGRES_PASSWORD:-change_this_password}@postgres:5432/enterprise_ai_strategy?sslmode=disable"
    ports:
      - "9187:9187"
    depends_on:
      - postgres
    restart: unless-stopped
    networks:
      - enterprise-ai-network

  # Redis Exporter for Prometheus
  redis-exporter:
    image: oliver006/redis_exporter
    container_name: enterprise-ai-redis-exporter
    environment:
      REDIS_ADDR: "redis://redis:6379"
      REDIS_PASSWORD: ${REDIS_PASSWORD:-change_this_password}
    ports:
      - "9121:9121"
    depends_on:
      - redis
    restart: unless-stopped
    networks:
      - enterprise-ai-network

  # Node Exporter for system metrics
  node-exporter:
    image: prom/node-exporter:latest
    container_name: enterprise-ai-node-exporter
    command:
      - '--path.rootfs=/host'
    volumes:
      - '/:/host:ro,rslave'
    ports:
      - "9100:9100"
    restart: unless-stopped
    networks:
      - enterprise-ai-network

  # Alertmanager for alert handling
  alertmanager:
    image: prom/alertmanager:latest
    container_name: enterprise-ai-alertmanager
    command:
      - '--config.file=/etc/alertmanager/config.yml'
      - '--storage.path=/alertmanager'
      - '--web.external-url=http://localhost:9093'
    volumes:
      - ./monitoring/alertmanager.yml:/etc/alertmanager/config.yml:ro
      - alertmanager_data:/alertmanager
    ports:
      - "9093:9093"
    restart: unless-stopped
    networks:
      - enterprise-ai-network

  # Jaeger for distributed tracing
  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: enterprise-ai-jaeger
    environment:
      - COLLECTOR_OTLP_ENABLED=true
    ports:
      - "16686:16686"
      - "14268:14268"
      - "14250:14250"
      - "4317:4317"   # OTLP gRPC receiver
      - "4318:4318"   # OTLP HTTP receiver
    restart: unless-stopped
    networks:
      - enterprise-ai-network

  # ELK Stack for centralized logging
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.8.0
    container_name: enterprise-ai-elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
    restart: unless-stopped
    networks:
      - enterprise-ai-network

  logstash:
    image: docker.elastic.co/logstash/logstash:8.8.0
    container_name: enterprise-ai-logstash
    volumes:
      - ./monitoring/logstash/pipeline:/usr/share/logstash/pipeline:ro
      - ./monitoring/logstash/config:/usr/share/logstash/config:ro
      - ./logs:/logs:ro
    ports:
      - "5044:5044"
      - "5000:5000"
    depends_on:
      - elasticsearch
    restart: unless-stopped
    networks:
      - enterprise-ai-network

  kibana:
    image: docker.elastic.co/kibana/kibana:8.8.0
    container_name: enterprise-ai-kibana
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
    restart: unless-stopped
    networks:
      - enterprise-ai-network

  # MinIO for object storage (S3-compatible)
  minio:
    image: minio/minio:latest
    container_name: enterprise-ai-minio
    command: server /data --console-address ":9001"
    environment:
      - MINIO_ROOT_USER=${MINIO_ROOT_USER:-admin}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD:-change_this_password}
    volumes:
      - minio_data:/data
    ports:
      - "9000:9000"
      - "9001:9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    restart: unless-stopped
    networks:
      - enterprise-ai-network

  # Backup Service
  backup:
    image: postgres:15-alpine
    container_name: enterprise-ai-backup
    environment:
      - PGPASSWORD=${POSTGRES_PASSWORD:-change_this_password}
    volumes:
      - ./database/backup:/backup
      - ./scripts/backup.sh:/backup.sh:ro
    command: ["sh", "/backup.sh"]
    depends_on:
      - postgres
    restart: "no"
    networks:
      - enterprise-ai-network

# Named volumes for data persistence
volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  alertmanager_data:
    driver: local
  elasticsearch_data:
    driver: local
  minio_data:
    driver: local

# Network configuration
networks:
  enterprise-ai-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16